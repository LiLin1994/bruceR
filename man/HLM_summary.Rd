% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/bruceR_regress.R
\name{HLM_summary}
\alias{HLM_summary}
\title{Summary results of HLM (\code{lmer} and \code{glmer} fitted by \code{lmerTest} package)}
\usage{
HLM_summary(model = NULL, level2.predictors = "", vartypes = NULL,
  t2r = FALSE, test.rand = FALSE, nsmall = 3, ...)
}
\arguments{
\item{model}{A model fitted by \code{lmer} or \code{glmer} function using the \code{lmerTest} package.}

\item{level2.predictors}{\strong{[only for \code{lmer}]} Optional.
If you have predictors at level 2, besides putting them into the formula in the \code{lmer} function as usual,
you should \strong{also} define here the grouping/clustering (level-2) variables and corresponding level-2 predictor variables.

*** Example: \code{level2.predictors="School: W1 + W2; House: 1"},
where \code{School} and \code{House} are two grouping variables,
\code{W1 & W2} are school-level predictors,
and there is no house-level predictor.

*** If there is no level-2 predictor in the formula of \code{lmer}, just leave this parameter blank.}

\item{vartypes}{\strong{[only for \code{lmer}]} Manually setting variable types. Needless in most situations.}

\item{t2r}{\strong{[only for \code{lmer}]} \code{T} or \code{F} (default).
Add a column of another kind of multilevel effect sizes: standardized partial effect size \emph{r} by \emph{t}-to-\emph{r} transformation.
See an example in Wei et al.'s paper (2017, \emph{Nature Human Behaviour}).
However, I personally did not recommend reporting this \emph{r}, because it could be misleading and sometimes ridiculous (e.g., an actually small effect may surprisingly have an \emph{r} > 0.6, and the interpretation of this \emph{r} is not the same as the Pearson's \emph{r} we are familiar with).}

\item{test.rand}{\strong{[only for \code{lmer} and \code{glmer}]} \code{T} or \code{F} (default).
Test random effects (i.e., variance components) by using the likelihood-ratio test (LRT), which is asymptotically chi-square distributed. For large datasets, it is much time-consuming.

*** Note that its results would be different from those in the default output of \code{HLM_summary()} (see "Wald \emph{Z} test" in the output),
because they differ in the principle of statistics. The LRT is based on model comparison and the reduction of AIC, whereas the Wald \emph{Z} test is estimated by approximation.
The Wald \emph{Z} test can also be seen in the output of SPSS (the \code{MIXED} syntax).}

\item{nsmall}{Number of decimal places of output. Default is 3.
But for some statistics (e.g., \emph{R}^2, ICC), to provide more precise information, we fix the decimal places to 5.}
}
\description{
Nice report of \strong{Hierarchical Linear Model (HLM)}, also known as \strong{Multilevel Linear Model (MLM)} or \strong{Linear Mixed Model (LMM)}.
HLM, MLM, or LMM (the same) refers to a model with nested data (e.g., Level-1: participants, Level-2: city; or Level-1: repeated-measures within a participant, Level-2: participants).
}
\details{
Hierarchical Linear Model (HLM), aka. Multilevel Linear Model (MLM) or Linear Mixed Model (LMM), is more complex than General Linear Model (GLM; i.e., OLS regression).
Predictor variables at different levels may have five types:
\describe{
  \item{1. Intercept}{The overall intercept (\eqn{\gamma_00})}
  \item{2. L1fixed}{Level-1 predicter with \strong{fixed} slope}
  \item{3. L1random-GROUP-L1VAR}{Level-1 predicter with \strong{random} slopes nested with a grouping/clustering variable}
  \item{4. L2-GROUP}{Level-2 predicter (e.g., GDP per capita at city level), always with \strong{fixed} slope unless there is also a level-3 structure.

*** NOTE: the current version of \code{'HLM_summary'} function does not consider three-levels design, so you may only use this function in two-levels HLM or cross-classified HLM.}
  \item{5. Cross-GROUP-L1VAR}{Cross-level interaction consisting of level-1 and level-2 predictors}
}
The degrees of freedom (\emph{df}) of predictor variables in HLM vary across different levels and also depend on the variable types.
However, different softwares use different estimation methods and thus provide somewhat different \emph{df}s, which may be confusing.
Whereas the \code{lmerTest} package in R provides \emph{df}s that are estimated by the Satterthwaite's (1946) approximation (i.e., a data-driven approach without defining variable types),
the \code{HLM} software provides \emph{df}s that totally depend on the variable types (i.e., a theory-driven approach).
}
\examples{
## To run the following examples:
# example("HLM_summary")

library(lmerTest)

## Example 1: data from lme4::sleepstudy
# 1) 'Subject' is a grouping/clustering variable
# 2) 'Days' is a level-1 predictor nested within 'Subject'
# 3) No level-2 predictors
m1=lmer(Reaction ~ (1 | Subject), data=sleepstudy)
m2=lmer(Reaction ~ Days + (1 | Subject), data=sleepstudy)
m3=lmer(Reaction ~ Days + (Days | Subject), data=sleepstudy)
HLM_summary(m1)
HLM_summary(m2)
HLM_summary(m3)

## Example 2: data from lmerTest::carrots
# 1) 'Constomer' is a grouping/clustering variable
# 2) 'Sweetness' is a level-1 predictor
# 3) 'Gender', 'Age', and 'Frequency' are level-2 predictors
hlm.1=lmer(Preference ~ Sweetness + Gender * Age + Frequency + (1 | Consumer), data=carrots)
hlm.2=lmer(Preference ~ Sweetness + Gender * Age + Frequency + (Sweetness | Consumer) + (1 | Product), data=carrots)
HLM_summary(hlm.1, level2.predictors="Consumer: Gender + Age + Frequency")
HLM_summary(hlm.2, level2.predictors="Consumer: Gender + Age + Frequency")
# anova(hlm.1, hlm.2)

## Example 3: data from MASS::bacteria
# GLMM with binomial outcome (multilvel logistic regression)
data.glmm=MASS::bacteria
data.glmm$week.2=(data.glmm$week>2) \%>\% as.numeric()
glmm=glmer(y ~ trt + week.2 + (1 | ID), data=data.glmm, family=binomial)
HLM_summary(glmm)

## To see notes on the statistics reported by 'HLM_summary()'
HLM_summary_notes()
}
\references{
(see Nakagawa & Schielzeth, 2013) (see Xu, 2003)
}
\seealso{
\code{\link{GLM_summary}}, \code{\link{regress}}
}
